---
@inproceedings{hyperx,
author = {Domke, Jens and Matsuoka, Satoshi and Ivanov, Ivan R. and Tsushima, Yuki and Yuki, Tomoya and Nomura, Akihiro and Miura, Shin'ichi and McDonald, Nie and Floyd, Dennis L. and Dub\'{e}, Nicolas},
title = {HyperX Topology: First at-Scale Implementation and Comparison to the Fat-Tree},
year = {2019},
isbn = {9781450362290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3295500.3356140},
doi = {10.1145/3295500.3356140},
abstract = {The de-facto standard topology for modern HPC systems and data-centers are Folded Clos networks, commonly known as Fat-Trees. The number of network endpoints in these systems is steadily increasing. The switch radix increase is not keeping up, forcing an increased path length in these multi-level trees that will limit gains for latency-sensitive applications. Additionally, today's Fat-Trees force the extensive use of active optical cables which carries a prohibitive cost-structure at scale. To tackle these issues, researchers proposed various low-diameter topologies, such as Dragonfly. Another novel, but only theoretically studied, option is the HyperX. We built the world's first 3 Pflop/s supercomputer with two separate networks, a 3--level Fat-Tree and a 12\texttimes{}8 HyperX. This dual-plane system allows us to perform a side-by-side comparison using a broad set of benchmarks. We show that the HyperX, together with our novel communication pattern-aware routing, can challenge the performance of, or even outperform, traditional Fat-Trees.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {40},
numpages = {23},
keywords = {network topology, fat-tree, PARX, InfiniBand, HyperX, routing},
location = {Denver, Colorado},
series = {SC '19},
selected={true},

abbr = {SC '19},
},
@inproceedings{polygeist-gpu-to-cpu,
author = {Moses, William S. and Ivanov, Ivan R. and Domke, Jens and Endo, Toshio and Doerfert, Johannes and Zinenko, Oleksandr},
title = {High-Performance GPU-to-CPU Transpilation and Optimization via High-Level Parallel Constructs},
year = {2023},
isbn = {9798400700156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3572848.3577475},
doi = {10.1145/3572848.3577475},
abstract = {While parallelism remains the main source of performance, architectural implementations and programming models change with each new hardware generation, often leading to costly application re-engineering. Most tools for performance portability require manual and costly application porting to yet another programming model.We propose an alternative approach that automatically translates programs written in one programming model (CUDA), into another (CPU threads) based on Polygeist/MLIR. Our approach includes a representation of parallel constructs that allows conventional compiler transformations to apply transparently and without modification and enables parallelism-specific optimizations. We evaluate our framework by transpiling and optimizing the CUDA Rodinia benchmark suite for a multi-core CPU and achieve a 58% geomean speedup over handwritten OpenMP code. Further, we show how CUDA kernels from PyTorch can efficiently run and scale on the CPU-only Supercomputer Fugaku without user intervention. Our PyTorch compatibility layer making use of transpiled CUDA PyTorch kernels outperforms the PyTorch CPU native backend by 2.7\texttimes{}.},
booktitle = {Proceedings of the 28th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming},
pages = {119â€“134},
numpages = {16},
keywords = {MLIR, polygeist, CUDA, barrier synchronization},
location = {Montreal, QC, Canada},
series = {PPoPP '23},
selected={true},

abbr = {PPoPP '23},
pdf = {polygeist-ppopp23-final.pdf},
},
@INPROCEEDINGS {polygeist-coarsening,
author = {I. R. Ivanov and O. Zinenko and J. Domke and T. Endo and W. S. Moses},
booktitle = {2024 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
title = {Retargeting and Respecializing GPU Workloads for Performance Portability},
year = {2024},
volume = {},
issn = {},
pages = {119-132},
abstract = {In order to come close to peak performance, accelerators like GPUs require significant architecture-specific tuning that understand the availability of shared memory, parallelism, tensor cores, etc. Unfortunately, the pursuit of higher performance and lower costs have led to a significant diversification of architecture designs, even from the same vendor. This creates the need for performance portability across different GPUs, especially important for programs in a particular programming model with a certain architecture in mind. Even when the program can be seamlessly executed on a different architecture, it may suffer a performance penalty due to it not being sized appropriately to the available hardware resources such as fast memory and registers, let alone not using newer advanced features of the architecture. We propose a new approach to improving performance of (legacy) CUDA programs for modern machines by automatically adjusting the amount of work each parallel thread does, and the amount of memory and register resources it requires. By operating within the MLIR compiler infrastructure, we are able to also target AMD GPUs by performing automatic translation from CUDA and simultaneously adjust the program granularity to fit the size of target GPUs. Combined with autotuning assisted by the platform-specific compiler, our approach demonstrates 27% geomean speedup on the Rodinia benchmark suite over baseline CUDA implementation as well as performance parity between similar NVIDIA and AMD GPUs executing the same CUDA program.},
keywords = {costs;codes;memory management;graphics processing units;hardware;software;registers},
doi = {10.1109/CGO57630.2024.10444828},
url = {https://doi.ieeecomputersociety.org/10.1109/CGO57630.2024.10444828},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar},

pdf = {polygeist-gpu-cgo24-preprint.pdf},
abbr = {CGO '24},
},
@misc{ivanov2024inputgen,
title={Input-Gen: Guided Generation of Stateful Inputs for Testing, Tuning, and Training},
author={Ivan R. Ivanov and Joachim Meyer and Aiden Grossman and William S. Moses and Johannes Doerfert},
year={2024},
month={jun},
eprint={2406.08843},
archivePrefix={arXiv},
publisher = {arXiv},
abstract = {The size and complexity of software applications is increasing at an accelerating pace. Source code repositories (along with their dependencies) require vast amounts of labor to keep them tested, maintained, and up to date. As the discipline now begins to also incorporate automatically generated programs, automation in testing and tuning is required to keep up with the pace - let alone reduce the present level of complexity. While machine learning has been used to understand and generate code in various contexts, machine learning models themselves are trained almost exclusively on static code without inputs, traces, or other execution time information. This lack of training data limits the ability of these models to understand real-world problems in software. In this work we show that inputs, like code, can be generated automatically at scale. Our generated inputs are stateful, and appear to faithfully reproduce the arbitrary data structures and system calls required to rerun a program function. By building our tool within the compiler, it both can be applied to arbitrary programming languages and architectures and can leverage static analysis and transformations for improved performance. Our approach is able to produce valid inputs, including initial memory states, for 90% of the ComPile dataset modules we explored, for a total of 21.4 million executable functions. Further, we find that a single generated input results in an average block coverage of 37%, whereas guided generation of five inputs improves it to 45%. },
primaryClass={id='cs.SE' full_name='Software Engineering' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers design tools, software metrics, testing and debugging, programming environments, etc. Roughly includes material in all of ACM Subject Classes D.2, except that D.2.4 (program verification) should probably have Logics in Computer Science as the primary subject area.'},

pdf = {input-gen-arxiv.pdf},
abbr = {arXiv},
}
---
